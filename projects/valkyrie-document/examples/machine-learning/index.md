# æœºå™¨å­¦ä¹ 

Valkyrie ä¸ºæœºå™¨å­¦ä¹ æä¾›äº†åŸºäº Array å’Œ ArrayND çš„é«˜æ•ˆæ•°å€¼è®¡ç®—æ”¯æŒï¼Œä¸“æ³¨äºå®ç”¨çš„æœºå™¨å­¦ä¹ ç®—æ³•å’Œæ•°æ®å¤„ç†ã€‚

## ç›¸å…³ç¤ºä¾‹

- [ç½‘ç»œçˆ¬è™«](web-crawler.md) - ç”¨äºæ•°æ®æ”¶é›†çš„é«˜æ€§èƒ½å¼‚æ­¥çˆ¬è™«æ¡†æ¶

## æ ¸å¿ƒæ•°ç»„ç±»å‹

- `Array1D` - ä¸€ç»´æ•°ç»„ï¼Œç”¨äºå‘é‡å’Œç‰¹å¾å¤„ç†
- `ArrayND` - å¤šç»´æ•°ç»„ï¼Œç”¨äºçŸ©é˜µè¿ç®—å’Œæ‰¹é‡æ•°æ®å¤„ç†
- å†…ç½®å¼‚æ„è®¡ç®—æ”¯æŒï¼Œå¯åœ¨ CPU/GPU é—´æ— ç¼åˆ‡æ¢

## æ•°æ®å¤„ç†

### åŸºæœ¬æ•°æ®æ“ä½œ

```valkyrie
# åˆ›å»ºå’ŒåŠ è½½æ•°æ®
let features = ArrayND::from_csv("data/features.csv")  # ç‰¹å¾çŸ©é˜µ
let labels = Array1D::from_csv("data/labels.csv")     # æ ‡ç­¾å‘é‡

# æ•°æ®é¢„å¤„ç†
let normalized = features.normalize()  # æ ‡å‡†åŒ–
let centered = features - features.mean(axis=0)  # ä¸­å¿ƒåŒ–

# æ•°æ®åˆ†å‰²
let (X_train, X_test, y_train, y_test) = train_test_split(
    features, labels, test_size=0.2, random_state=42
)
```

### ç‰¹å¾å·¥ç¨‹

```valkyrie
# ç‰¹å¾ç¼©æ”¾
let scaled_features = features.standardize()  # æ ‡å‡†åŒ– (z-score)
let normalized_features = features.normalize(min=0.0, max=1.0)  # å½’ä¸€åŒ–

# ç‰¹å¾é€‰æ‹©
let selected = features.select_by_variance(threshold=0.01)
let top_features = features.select_k_best(k=10, target=labels)

# ç‰¹å¾å˜æ¢
let polynomial = features.polynomial_features(degree=2)
let log_transformed = features.log_transform()
```

## æœºå™¨å­¦ä¹ ç®—æ³•

### çº¿æ€§æ¨¡å‹

```valkyrie
# çº¿æ€§å›å½’ - ä½¿ç”¨çŸ©é˜µè¿ç®—
let ğ— = X_train.add_bias_column()  # æ·»åŠ åç½®åˆ—
let ğ° = (ğ—áµ€ Â· ğ—)â»Â¹ Â· ğ—áµ€ Â· y_train  # æœ€å°äºŒä¹˜è§£
let predictions = X_test.add_bias_column() Â· ğ°

# å²­å›å½’ - å¸¦æ­£åˆ™åŒ–
let Î» = 0.1
let ğˆ = ArrayND::eye(ğ—.shape()[1])
let ğ°_ridge = (ğ—áµ€ Â· ğ— + Î» * ğˆ)â»Â¹ Â· ğ—áµ€ Â· y_train

# é€»è¾‘å›å½’ - sigmoidæ¿€æ´»
let Ïƒ = |z: ArrayND| 1.0 / (1.0 + (-z).exp())  # sigmoidå‡½æ•°
let logits = X_test Â· ğ°
let probabilities = Ïƒ(logits)
```

### èšç±»ç®—æ³•

```valkyrie
# K-Means èšç±» - ä½¿ç”¨æ•°ç»„æ“ä½œ
let k = 3
let centroids = ArrayND::random([k, X_train.shape()[1]])  # éšæœºåˆå§‹åŒ–è´¨å¿ƒ

for iteration in 0..100 {
    # è®¡ç®—è·ç¦»çŸ©é˜µ
    let distances = X_train.cdist(centroids)  # [n_samples, k]
    let assignments = distances.argmin(axis=1)  # æœ€è¿‘è´¨å¿ƒç´¢å¼•
    
    # æ›´æ–°è´¨å¿ƒ
    for cluster in 0..k {
        let mask = assignments.eq(cluster)
        let cluster_points = X_train.masked_select(mask)
        if cluster_points.shape()[0] > 0 {
            centroids.row_mut(cluster).copy_from(cluster_points.mean(axis=0))
        }
    }
}
```

### K-Means èšç±»

```valkyrie
# K-Means èšç±» - ä½¿ç”¨æ•°ç»„æ“ä½œ
let k = 3
let centroids = ArrayND::random([k, X_train.shape()[1]])  # éšæœºåˆå§‹åŒ–è´¨å¿ƒ

for iteration in 0..100 {
    # è®¡ç®—è·ç¦»çŸ©é˜µ
    let distances = X_train.cdist(centroids)  # [n_samples, k]
    let assignments = distances.argmin(axis=1)  # æœ€è¿‘è´¨å¿ƒç´¢å¼•
    
    # æ›´æ–°è´¨å¿ƒ
    for cluster in 0..k {
        let mask = assignments.eq(cluster)
        let cluster_points = X_train.masked_select(mask)
        if cluster_points.shape()[0] > 0 {
            centroids.row_mut(cluster).copy_from(cluster_points.mean(axis=0))
        }
    }
}
```

## é™ç»´ç®—æ³•

```valkyrie
# ä¸»æˆåˆ†åˆ†æ (PCA) - ä½¿ç”¨çŸ©é˜µåˆ†è§£
let ğ—_centered = X_train - Î¼  # ä¸­å¿ƒåŒ–ï¼ŒÎ¼ = X_train.mean(axis=0)
let Î£ = ğ—_centeredáµ€ Â· ğ—_centered / (X_train.shape()[0] - 1)  # åæ–¹å·®çŸ©é˜µ
let (Î», ğ•) = Î£.eig()  # ç‰¹å¾åˆ†è§£ï¼šÎ»ä¸ºç‰¹å¾å€¼ï¼Œğ•ä¸ºç‰¹å¾å‘é‡

# é€‰æ‹©å‰kä¸ªä¸»æˆåˆ†
let k = 2
let ğ•_k = ğ•.slice([.., 0..k])  # å‰kä¸ªç‰¹å¾å‘é‡
let ğ—_pca = ğ—_centered Â· ğ•_k  # æŠ•å½±åˆ°ä¸»æˆåˆ†ç©ºé—´
```

## æ¨¡å‹è¯„ä¼°

```valkyrie
# åŸºæœ¬è¯„ä¼°æŒ‡æ ‡ - ä½¿ç”¨æ•°ç»„è®¡ç®—
let correct = y_true.eq(y_pred).sum()  # æ­£ç¡®é¢„æµ‹æ•°é‡
let accuracy = correct.to_f64() / y_true.len() as f64

# å›å½’æŒ‡æ ‡
let Îµ = y_true - y_pred  # æ®‹å·®
let MSE = (ÎµÂ² ).mean()   # å‡æ–¹è¯¯å·®
let MAE = |Îµ|.mean()     # å¹³å‡ç»å¯¹è¯¯å·®
let RMSE = âˆšMSE          # å‡æ–¹æ ¹è¯¯å·®
```

## æ•°ç»„æ“ä½œç¤ºä¾‹

```valkyrie
# æ•°æ®åˆ†å‰² - ä½¿ç”¨æ•°ç»„ç´¢å¼•
let n_samples = X.shape()[0]
let train_size = (n_samples as f64 * 0.8) as usize
let indices = ArrayND::arange(n_samples).shuffle()  # éšæœºæ‰“ä¹±ç´¢å¼•

let train_indices = indices.slice([0..train_size])
let test_indices = indices.slice([train_size..])

let X_train = X.index_select(train_indices, axis=0)
let X_test = X.index_select(test_indices, axis=0)
let y_train = y.index_select(train_indices, axis=0)
let y_test = y.index_select(test_indices, axis=0)
```
        
        # å½“ç¼“å†²åŒºæ»¡æ—¶è¿›è¡Œæ‰¹é‡æ›´æ–°
## æ€»ç»“

æœ¬æ–‡æ¡£å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Valkyrie çš„ Array å’Œ ArrayND ç±»å‹è¿›è¡Œæœºå™¨å­¦ä¹ ä»»åŠ¡ã€‚é‡ç‚¹å…³æ³¨æ•°ç»„æ“ä½œçš„å®é™…ä½¿ç”¨ï¼ŒåŒ…æ‹¬ï¼š

- æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹
- åŸºæœ¬æœºå™¨å­¦ä¹ ç®—æ³•çš„æ•°ç»„å®ç°
- èšç±»å’Œé™ç»´çš„çŸ©é˜µè¿ç®—
- æ¨¡å‹è¯„ä¼°çš„æ•°ç»„è®¡ç®—
- æ•°æ®åˆ†å‰²å’Œç´¢å¼•æ“ä½œ

é€šè¿‡è¿™äº›ç¤ºä¾‹ï¼Œæ‚¨å¯ä»¥äº†è§£å¦‚ä½•åˆ©ç”¨ Valkyrie çš„å†…ç½®æ•°ç»„åŠŸèƒ½æ¥æ„å»ºæœºå™¨å­¦ä¹ åº”ç”¨ã€‚
for (name, (mean, std)) in results {
    println!("{}: {:.3} (+/- {:.3})", name, mean, std * 2)
}
```

### 3. ç‰¹å¾å·¥ç¨‹è‡ªåŠ¨åŒ–

```valkyrie
# è‡ªåŠ¨ç‰¹å¾å·¥ç¨‹
let feature_engineer = AutoFeatureEngineering::new()
    .polynomial_features(degree: 2)
    .interaction_features(true)
    .log_transform(columns: vec!["income", "age"])
    .binning(column: "age", bins: 5)

let engineered_features = feature_engineer.fit_transform(X)
```

Valkyrie çš„æœºå™¨å­¦ä¹ ç‰¹æ€§æä¾›äº†å®Œæ•´çš„å·¥å…·é“¾ï¼Œä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹éƒ¨ç½²ï¼Œæ”¯æŒä¼ ç»Ÿæœºå™¨å­¦ä¹ å’Œç°ä»£æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œä¸ºæ•°æ®ç§‘å­¦å®¶å’Œæœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆæä¾›äº†å¼ºå¤§è€Œçµæ´»çš„å¼€å‘ç¯å¢ƒã€‚