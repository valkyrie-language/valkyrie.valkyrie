# Valkyrie Lexer
# Implemented in Valkyrie language

let Token = {type = "", value = "", line = 0, column = 0}
let TokenType = {
    LET = "LET",
    MICRO = "MICRO",
    EXPORT = "EXPORT",
    IF = "IF",
    ELSE = "ELSE",
    WHILE = "WHILE",
    FUNCTION = "FUNCTION",
    RETURN = "RETURN",
    IDENTIFIER = "IDENTIFIER",
    NUMBER = "NUMBER",
    STRING = "STRING",
    BOOLEAN = "BOOLEAN",
    ASSIGN = "ASSIGN",
    PLUS = "PLUS",
    MINUS = "MINUS",
    MULTIPLY = "MULTIPLY",
    DIVIDE = "DIVIDE",
    MODULO = "MODULO",
    EQUAL = "EQUAL",
    NOT_EQUAL = "NOT_EQUAL",
    NOT = "NOT",
    LESS = "LESS",
    GREATER = "GREATER",
    LE = "LE",
    GE = "GE",
    AND = "AND",
    OR = "OR",
    LPAREN = "LPAREN",
    RPAREN = "RPAREN",
    LBRACE = "LBRACE",
    RBRACE = "RBRACE",
    LBRACKET = "LBRACKET",
    RBRACKET = "RBRACKET",
    COMMA = "COMMA",
    SEMICOLON = "SEMICOLON",
    COLON = "COLON",
    DOT = "DOT",
    ARROW = "ARROW",
    TRUE = "TRUE",
    FALSE = "FALSE",
    EOF = "EOF",
    COMMENT = "COMMENT"
}
let Lexer = {source = "", position = 0, line = 1, column = 1, tokens = [], keywords = {}}

micro initLexer(source) {
    let lexer = {}
    lexer.source = source
    lexer.position = 0
    lexer.line = 1
    lexer.column = 1
    lexer.tokens = []
    lexer.keywords = {}
    lexer.keywords["let"] = "LET"
    lexer.keywords["micro"] = "MICRO"
    lexer.keywords["export"] = "EXPORT"
    lexer.keywords["if"] = "IF"
    lexer.keywords["else"] = "ELSE"
    lexer.keywords["while"] = "WHILE"
    lexer.keywords["function"] = "FUNCTION"
    lexer.keywords["return"] = "RETURN"
    lexer.keywords["true"] = "TRUE"
    lexer.keywords["false"] = "FALSE"
    return lexer
}

micro current(lexer) {
    if lexer.position >= lexer.source.length {
        ""
    } else {
        lexer.source[lexer.position]
    }
}

micro peek(lexer, offset) {
    let pos = lexer.position + offset
    if pos >= lexer.source.length {
        ""
    } else {
        lexer.source[pos]
    }
}

micro advance(lexer) {
    if lexer.position < lexer.source.length {
        if lexer.source[lexer.position] == "\n" {
            lexer.line = lexer.line + 1
            lexer.column = 1
        } else {
            lexer.column = lexer.column + 1
        }
        lexer.position = lexer.position + 1
    }
}

micro skipWhitespace(lexer) {
    while current(lexer) == " " ||
    current(lexer) == "\t" ||
    current(lexer) == "\r" ||
    current(lexer) == "\n" {
        advance(lexer)
    }
}

# Character classification functions
micro isAlpha(char) {
    (char >= "a" && char <= "z") || (char >= "A" && char <= "Z") || char == "_"
}

micro isDigit(char) {
    char >= "0" && char <= "9"
}

micro isAlphaNumeric(char) {
    isAlpha(char) || isDigit(char)
}

micro readIdentifier(lexer) {
    let startLine = lexer.line
    let startColumn = lexer.column
    let start = lexer.position
    while isAlphaNumeric(current(lexer)) {
        advance(lexer)
    }
    let value = lexer.source.substring(start, lexer.position)
    
    # Check if it's a keyword
    let tokenType = "IDENTIFIER"
    if lexer.keywords[value] {
        tokenType = lexer.keywords[value]
    }
    
    let token = {}
    token.type = tokenType
    token.value = value
    token.line = startLine
    token.column = startColumn
    token
}

micro readNumber(lexer) {
    let startLine = lexer.line
    let startColumn = lexer.column
    let start = lexer.position
    while isDigit(current(lexer)) {
        advance(lexer)
    }
    if current(lexer) == "." && isDigit(peek(lexer, 1)) {
        advance(lexer)
        while isDigit(current(lexer)) {
            advance(lexer)
        }
    }
    let value = lexer.source.substring(start, lexer.position)
    
    let token = {}
    token.type = "NUMBER"
    token.value = value
    token.line = startLine
    token.column = startColumn
    token
}

micro readString(lexer) {
    let startLine = lexer.line
    let startColumn = lexer.column
    let quote = current(lexer)
    advance(lexer)
    let start = lexer.position
    while current(lexer) != quote && current(lexer) != "" {
        if current(lexer) == "\\" {
            advance(lexer)
        }
        advance(lexer)
    }
    let value = lexer.source.substring(start, lexer.position)
    if current(lexer) == quote {
        advance(lexer)
    }
    
    let token = {}
    token.type = "STRING"
    token.value = value
    token.line = startLine
    token.column = startColumn
    token
}

# Read comment
micro readComment(lexer) {
    let startLine = lexer.line
    let startColumn = lexer.column
    advance(lexer) # Skip #
    
    let value = ""
    while current(lexer) != "" && current(lexer) != "\n" {
        value = value + current(lexer)
        advance(lexer)
    }
    
    let token = {}
    token.type = "COMMENT"
    token.value = value
    token.line = startLine
    token.column = startColumn
    token
}

# Create Token
micro createToken(type, value, line, column) {
    let token = {}
    token.type = type
    token.value = value
    token.line = line
    token.column = column
    token
}

micro tokenize(lexer) {
          while (lexer.position < lexer.source.length) {
              skipWhitespace(lexer);
              let char = current(lexer);
              if (char == "") {
                  break;
              }

              let line = lexer.line;
              let column = lexer.column;

              if (char == "#") {
                  let comment = readComment(lexer);
                  lexer.tokens.push(comment);
              } else if (char == "\"") {
                  let str = readString(lexer);
                  lexer.tokens.push(str);
              } else if (char >= "0" && char <= "9") {
                  let num = readNumber(lexer);
                  lexer.tokens.push(num);
              } else if ((char >= "a" && char <= "z") || (char >= "A" && char <= "Z") || char == "_") {
                  let id = readIdentifier(lexer);
                  lexer.tokens.push(id);
              } else if (char == "=" && peek(lexer, 1) == "=") {
                  let token = createToken("EQUAL", "==", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
                  advance(lexer);
              } else if (char == "!" && peek(lexer, 1) == "=") {
                  let token = createToken("NOT_EQUAL", "!=", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
                  advance(lexer);
              } else if (char == "!") {
                  let token = createToken("NOT", "!", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == "-" && peek(lexer, 1) == ">") {
                  let token = createToken("ARROW", "->", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
                  advance(lexer);
              } else if (char == "=") {
                  let token = createToken("ASSIGN", "=", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == "+") {
                  let token = createToken("PLUS", "+", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == "-") {
                  let token = createToken("MINUS", "-", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == "*") {
                  let token = createToken("MULTIPLY", "*", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == "/") {
                  let token = createToken("DIVIDE", "/", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == "<") {
                  if (peek(lexer, 1) == "=") {
                      let token = createToken("LE", "<=", line, column);
                      lexer.tokens.push(token);
                      advance(lexer);
                      advance(lexer);
                  } else {
                      let token = createToken("LESS", "<", line, column);
                      lexer.tokens.push(token);
                      advance(lexer);
                  }
              } else if (char == ">") {
                  if (peek(lexer, 1) == "=") {
                      let token = createToken("GE", ">=", line, column);
                      lexer.tokens.push(token);
                      advance(lexer);
                      advance(lexer);
                  } else {
                      let token = createToken("GREATER", ">", line, column);
                      lexer.tokens.push(token);
                      advance(lexer);
                  }
              } else if (char == "&" && peek(lexer, 1) == "&") {
                  let token = createToken("AND", "&&", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
                  advance(lexer);
              } else if (char == "|" && peek(lexer, 1) == "|") {
                  let token = createToken("OR", "||", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
                  advance(lexer);
              } else if (char == "%") {
                  let token = createToken("MODULO", "%", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == "(") {
                  let token = createToken("LPAREN", "(", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == ")") {
                  let token = createToken("RPAREN", ")", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == "{") {
                  let token = createToken("LBRACE", "{", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == "}") {
                  let token = createToken("RBRACE", "}", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == "[") {
                  let token = createToken("LBRACKET", "[", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == "]") {
                  let token = createToken("RBRACKET", "]", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == ",") {
                  let token = createToken("COMMA", ",", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == ";") {
                  let token = createToken("SEMICOLON", ";", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == ":") {
                  let token = createToken("COLON", ":", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else if (char == ".") {
                  let token = createToken("DOT", ".", line, column);
                  lexer.tokens.push(token);
                  advance(lexer);
              } else {
            # Throw error for unknown character
            # Note: Valkyrie language may not support string interpolation yet, so use simple error message
            ValkyrieRuntime.assert(false, "Unexpected character in lexer")
            advance(lexer) # Prevent infinite loop
        }
          }

          let eofToken = createToken("EOF", "", lexer.line, lexer.column);
          lexer.tokens.push(eofToken);
          return lexer.tokens;
      }

export {
    TokenType,
    initLexer,
    tokenize
}